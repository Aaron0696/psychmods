---
title: "NUSmodAn"
author: "Aaron0696"
output:
  html_document:
    fig_align: center
    number_sections: false
    highlight: haddock
    theme: yeti
    toc: yes
    toc_float: yes
    toc_depth: 2
    df_print: paged
    fig_width: 4
    fig_height: 4
  github_document:
    toc: true
    toc_depth: 3
    fig_width: 4
    fig_height: 4
---
```{r render, eval = FALSE, include = FALSE}
# for github markdown
rmarkdown::render(input = "psychmods.Rmd",
                  output_format = "github_document",
                  output_file = "README.md")
# for html
rmarkdown::render(input = "psychmods.Rmd",
                  output_format = "html_document",
                  output_file = "docs/index.html")
```

# Introduction

My favourite part of university education was the autonomy to choose our modules. Excluding core and other compulsory modules, we were frequently spoiled for choice when it came to the electives. But this freedom came at a cost, we needed to bid for our modules instead of them being handed to us. The bidding system (**CORS**) was created by NUS to cope with the reality that some modules would be in higher demand, yet there is a limited supply of lecturers for the topic. Students had to carefully ration their limited bid points, which were used to win auctions for desired modules. Do you go all-in on an extremely popular module and be stuck with no points to bid for the remaining modules? Or spread the risk and bid moderately on multiple modules that align with your interest?  
  
Inadvertently, we began to observe, hypothesize and act on certain **trends** to guide and maximize our bidding choices. We might even share advices based on these trends. For example:

> Modules belonging to the domain of Clinical Psychology are the most popular, so you need to plan ahead and stockpile points from previous semesters if you plan on bidding for them.

This advice originated from numerous seniors and I even gave this advice to my juniors. I also became more convinced after observing peers griefing over their inability to secure a place in `Introduction to Counselling Psychology` or `Psychological Therapies` due to the exhorbitant amount of points required (which required students to stockpile points from previous semesters). But I have never heard anyone claiming that they really wanted to study `Cognitive Neuroscience` but failed to bid for it.

But is it really true that Clinical Psychology modules are the most popular? Rather than basing our advices on personal anecdotes and  observation, do we have **data** to support this claim? The answer is *yes*! Bidding and module data are available at https://nusmods.com/api/. Thanks to the team at NUSMods (https://nusmods.com/team) who created a great timetabling tool for all NUS students.

I downloaded, extracted, transform, analysis and visualized the information using R. The codes are available at github. The github repository contains extracted data for all modules from different majors and faculty but I will focus only on the Psychology modules in this post as I am more familiar with the Psychology department.

# What Are The Most Popular Modules

Are Clinical Psychology modules really the most popular? Lets see if the most popular modules do belong to Clinical Psychology. First, we would need some way to measure popularity. Luckily, the bidding statistics provides a few indicators of popularity. Lets start by defininig a popular module as possessing the following characteristic in Round 1A:

1) Maximum quota available for bidding.
    * Some background on the bidding system is needed. Round 1A is officially the first round of bidding but there is a *Module Preference Exercise* before Round 1A. In this exercise, all students declare the modules that they wish to study. 
        * When the total number of students that wish to study a particular module is less than the quota, then these students will simply be allocated that module for free. The remaining quota will be up for bidding in Round 1A. 
        * If the number of interested students exceed the quota, no students will be pre-allocated the module and the module will be put up for bidding in Round 1A with all quotas intact. We expect popular modules to fall into this scenario, thus their quota in Round 1A should be at a maximum.
2) Number of bidders exceed the quota.
3) Higher lowest successful bid. 
    * The lowest successful bid is the lowest bid that wins the auction, anyone who bid below that amount will not be allocated the module.
4) Higher number of bidders relative to the quota available.

These indicators were presented sequentially to indicate the reasoning that I will be using to shortlist the most popular modules. I will eliminate modules that do not fit the criteria set out in 1) and 2). 3) and 4) will be used as tiebreakers for modules that fulfil both 1) and 2).

Also, I will separately analyse the level 3 and level 4 modules.

# Trends

I selected three more trends to investigate.

> There used to be a time when Clinical Psychology modules were not popular.

I mentioned that there was a perceived trend that Clinical Psychology modules were really popular, but I recently met a few slightly more senior seniors in the workforce (who graduated almost a decade ago). They told me, much to my surprise, that Clinical Psychology was pretty unpopular back in their days. Was this supported by the data?

> A module is less popular when the lecture is early in the day.

Lessons at 8am were painful, I live somewhere in the North-East so I would have to wake up somewhere around 6.15am to arrive comfortably for 8am lessons (including time taken for the shuttle bus in NUS). I generalized from my personal opinion to form this myth, that 8am lessons would be less popular compared to their later counterparts. My friends generally shared the same sentiments, but was it reflected in the bidding statistics? Or are we projecting our laziness to other students?

> Module bidding became more competitive in later cohorts, you should bid some amount higher than previous winning bids to account for the inflation in points caused by the increased competitiveness.

Almost everyone checks the bidding statistics from previous iterations of the module to estimate the amount of points to bid. Of course, there should be a positive correlation between past and future bidding statistics but would it be recommended to **anchor** your bids onto the lowest successful bids from the past? If so, how much higher or lower should we bid compared to previous iterations? There are a few hypothesized reasons for the increased competitiveness, such as the cohort expanding but module quotas remanining constant. Or the tendency for students to always bid some points higher than previous winning bids, which leads to this upward cycle of bid point inflation. Does bid point inflation really exist?

# Myth 1: Modules belonging to the domain of Clinical or Social Psychology are the most popular.

First thing



* Notes:
    1. AY2017/2018 Semester 2 and AY2018/2019 Semester 2 bidding data not available.
    2. The bidding statistics are highly non-normal due to being bounded by zero (they cannot make negative bids or have negative bidders). May consider using zero-inflated or poisson regression if considering these statistics as dependent variables.

# Phase 1: Setting Up Environment, Packages And Loading Data {.tabset .tabset-fade}

## Packages And Options

```{r setup, warning = FALSE, message = FALSE}
library(semTools)
library(ggplot2)
library(rjson)
library(stringr)
library(DT)
library(psych)
library(corrplot)
library(tidyverse)
library(forcats)
library(lme4)
library(shiny)
library(semTools)
library(plotly)
options(width = 999)
knitr::opts_chunk$set(dpi = 300, out.width = "50%", eval = FALSE)
```

## Load Bidding Data

* Extract data from `nusmods` at https://api.nusmods.com/.
* After loading the data in `.JSON` format, convert to a dataframe.

```{r extract, eval=FALSE}
myjson <- fromJSON(file = url("https://api.nusmods.com/corsBiddingStatsRaw.json")) # read data directly from URL
myBid <- data.frame() # create empty dataframe which will act as a container to be populated with data
for(r in 1:length(myjson)) # for each element in the myjson list, append it to myBid
{
  if(myjson[[r]]$Semester == 1 | myjson[[r]]$Semester == 2) # if semester 1 or 2
  {
    myBid <- rbind(myBid, myjson[[r]]) # add to dataframe
  }
  myjson[[r]] <- NA # free up some RAM
}

saveRDS(myBid, file = "myBid.RDS") # save to directory
```

### Load `myBid.RDS`

* Downloading the data from the API using the code above takes a substantial amount of time.
* I saved the downloaded data in `myBid.RDS` and load it directly from my local folder while I worked on the project.

```{r loadbid}
myBid <- readRDS("myBid.RDS")
```    

## Load Module Information

* Module information was scattered across different folders.
* Used a loop to repeat the process of downloading and converting to dataframe across the different folders accessed by the different URLs.
    * The same concept was used to consolidate information about the Module Titles.

```{r extract2, eval=FALSE}
myModInfo <- data.frame() # create empty dataframe which will act as a container to be populated with data
for(year in c(2011:2018)) # looping through each year
{
  for(semester in c(1,2))
  {
    # create the url where data is to be extracted from
    myurl <- paste0("https://api.nusmods.com/", year, "-", year + 1, "/", semester, "/moduleTimetableDeltaRaw.json")
    myjson <- fromJSON(file = url(myurl))
    for(r in 1:length(myjson)) # for each element in the myjson list, append it to myModInfo
    {
      if(isTRUE(str_detect(myjson[[r]]$ModuleCode, "^PL"))) # only keep info if module code begins with PL
      {
        if(myjson[[r]]$Semester == 1 | myjson[[r]]$Semester == 2) # only get semester 1 and 2 information
        {
          myModInfo <- rbind(myModInfo, myjson[[r]]) # add to dataframe
        }
      }
      myjson[[r]] <- NA # replace the element with NA to free up some rAM
    }
    cat(year, "Semester", semester, "Done!") # progress tracker
  }
}

myTitles <- data.frame() # create empty dataframe which will act as a container to be populated with data
for(year in c(2014:2018)) # looping through each year
{
    myurl <- paste0("https://api.nusmods.com/", year, "-", year + 1, "/moduleList.json") # create the url where data is to be extracted from
    myjson <- fromJSON(file = url(myurl))
    for(r in 1:length(myjson)) # for each element in the myjson list, append it to myModInfo
    {
      if(isTRUE(str_detect(myjson[[r]]$ModuleCode, "^PL"))) # only keep info if module code begins with PL
      {
        if(paste0(myjson[[r]]$Semester, collapse = "|") == "1"|
           paste0(myjson[[r]]$Semester, collapse = "|") == "2"|
           paste0(myjson[[r]]$Semester, collapse = "|") == "1|2") # only keep information from semester 1 and 2
        {
          myTitles <- rbind(myTitles, as.data.frame(myjson[[r]])) # add to dataframe
        }
      }
      myjson[[r]] <- NA # free RAM
    }
}

myModInfo <- myTitles %>% # add titles information to myModInfo
  select(ModuleCode, ModuleTitle) %>% # select these two columns
  filter(ModuleTitle != "Lab in Applied Psychology") %>%
  distinct() %>% # remove duplicates
  right_join(myModInfo, by = "ModuleCode") # left = myTitles, right = myModInfo

saveRDS(myModInfo, file = "myModInfo.RDS") # save to directory
```

### Load `myModInfo.RDS`

* Downloading the data from the API using the code above takes a substantial amount of time.
* I saved the downloaded data in `myModInfo.RDS` and load the data directly while I worked on the project.

```{r loadmod}
myModInfo <- readRDS("myModInfo.RDS")
```

# Phase 2: Filter, Transform And Merge {.tabset .tabset-fade}
    
## Module Information

* Filter information from the dataframe `myModInfo`.
    * Removing non-Psychology modules.
    * Removing modules without module titles, these are modules that appeared before AY2014/2015 and never resurfaced afterwards.
    * Removing information about tutorials.

### Filter

```{r filtermod}
myModInfo <- myModInfo %>%
  select(-LastModified, -LastModified_js, -isDelete) %>% # remove these columns
  filter(str_detect(ModuleCode, "^PL")) %>% # removing non-Psychology modules
  filter(!is.na(ModuleTitle)) %>% # removing modules without module titles #PL3285, PL4220, PL4217
  filter(LessonType != "TUTORIAL") %>% # removing information about tutorials
  select(AcadYear, Semester, ModuleCode, ModuleTitle, DayText, StartTime, Semester) %>% # select these columns
  distinct() # remove duplicates

head(myModInfo) # peek
```  
    
## Bidding Information `myBid`

* Filter information from the dataframe `myBid`.
    * Removing non-Psychology modules, including Roots and Wings (prefixed with PLS-) and Psychology for non-Psychology students (prefixed with PLB-).
    * Removing information from quotas that are reserved and not available for bidding.
    * Removing information from modules with more than one lecture/seminar session.
    * Removing bidding information from non-psychology students.

### Filter

```{r filterbid}
myBid <- myBid %>%
  filter(str_detect(ModuleCode, "^PL")) %>% # removing non-Psychology modules
  filter(!str_detect(ModuleCode, "PLS|PLB")) %>% # remove PLS and PLB modules
  filter(!str_detect(StudentAcctType, "Reserved")) %>% # remove reserved rounds
  filter(!str_detect(StudentAcctType, "[G]")) %>% # remove bidding information from non-psychology students
  filter(!str_detect(paste0(unique(myBid$ModuleCode[grep("2",myBid$Group)]), collapse = "|"), ModuleCode)) %>% # remove modules that have more than one lecture
  select(-Faculty, -Group) # remove these columns

head(myBid) # peek
```

## Merge

* Combine the information of `myModInfo` and `myBid`.

```{r merge}
# modules that do not appear in both dataframes are dropped
mydata <- inner_join(myBid, 
                     myModInfo,
                     by = c("ModuleCode", "AcadYear", "Semester"))
```

# Phase 3: Data Wrangling {.tabset .tabset-fade}

* The variables available in the original data are useful but they are too specific to interpret meaningfully.
* This section creates new variables based on the original data and allow us to better discern any trend in the data.
* Also includes additional wrangling and manipulations to ease the plotting of graphs and analysis later.

## Coercing Columns

```{r transform2}
# transform these columns to numeric
for(r in c("Quota", "Bidders", "LowestBid", "LowestSuccessfulBid", "HighestBid", "StartTime"))
{
  mydata[,grep(r, names(mydata))] <- as.numeric(mydata[,grep(r, names(mydata))])
}
# transform these columns to factors
for(r in c("AcadYear", "Semester", "ModuleCode", "Round", "StudentAcctType", "DayText", "StudentAcctType", "ModuleTitle"))
{
  mydata[,grep(r, names(mydata))] <- factor(mydata[,grep(r, names(mydata))])
}
```

## Rearranging `DayText` Levels

```{r daytext}
mydata$DayText <- factor(mydata$DayText,
                         levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"))
```

## Shortening `StudentAcctType` Levels

```{r shortacct}
mydata <- mutate(mydata, StudentAcctType = fct_recode(StudentAcctType, 
                                                      "New[P]" = "New Students [P]",
                                                      "NUS[P]" = "NUS Students [P]",
                                                      "Return[P]" = "Returning Students [P]",
                                                      "ReturnNew[P]" = "Returning Students and New Students [P]"))
```

## New Variable: Level

```{r create1}
# create new variable that indicates the level of the module, based on their module code
mydata$Level <- factor(ifelse(str_detect(mydata$ModuleCode, "1[0-9][0-9][0-9]"), "Level 1",
                      ifelse(str_detect(mydata$ModuleCode, "2[0-9][0-9][0-9]"), "Level 2",
                             ifelse(str_detect(mydata$ModuleCode, "3[0-9][0-9][0-9]"), "Level 3",
                                    ifelse(str_detect(mydata$ModuleCode, "4[0-9][0-9][0-9]"), "Level 4", 
                                           "Graduate Module")))))
```

## New Variable: BidPerQuota

```{r create2}
# BidPerQuota = Bidders/Quota
mydata$BidPerQuota <- with(mydata, Bidders/Quota)
```

## New Variable: DayPeriod

```{r create3}
mydata$Period <- factor(ifelse(mydata$StartTime < 1200, "Morning", ">=Afternoon"),
                           levels = c("Morning", ">=Afternoon"))
```

## Vector Of Column Names

```{r colvecs}
# create vector of the column names which are factors
facnames <- mydata %>% select_if(is.factor) %>% names()
# facnames without ModuleCode and StudentAcctType
facnames.mod <- facnames[-grep("ModuleCode|ModuleTitle", facnames)]
# create vector ofthe column names which are numeric
numnames <- mydata %>% select_if(is.numeric) %>% names()
# numnames without StartTime
numnames.time <- names(select_if(mydata, is.numeric))[-grep("StartTime", numnames)]
```

# Phase 4: Data Diagnostics {.tabset .tabset-fade}

* Plot univariate histograms and bivariate plots using loops for **almost every** combination of variables.
* The graphs from this section are predominantly for diagnostics rather than exploration, what I mean is that the graphs from this section would make little sense if one tried to draw insights from them. This is because they are aggregated across all other variables.
    * For example: The mean of `Bidders` is calculated across all academic years, all bidding rounds, all modules...
* What I am looking out for in this section are odd patterns, like zeroes in places where they shouldn't be, missing data, highly non-normal data, variables with outliers, etc...
    
## Univariate Descriptive Statistics

```{r unides}
str(mydata)
select(describe(mydata), n, mean, sd, median, min, max, skew, kurtosis)
```

## Univariate Histograms/Boxplots {.tabset .tabset-fade .tabset-pills}

* Plots to illustrate the frequency/distribution of variables.

### Categorical Variables

```{r explore1, warning = FALSE}
# plot the categorical variables
for(r in facnames.mod)
{
  plot(
    ggplot(data = mydata, aes_string(x = r, fill = r)) + 
      geom_histogram(stat = "count") + 
      ylab("Count") +
      ggtitle(paste0("Count of ", r)) +
      theme_classic() + 
      theme(axis.text.x = element_text(angle = 90),
            axis.title.x = element_blank(),
            legend.position = "none")
  )
}
```

### Continuous Variables

```{r explore2, warning = FALSE}
# plot the continuous variables
for(r in numnames)
{
  plot(
    ggplot(data = mydata, aes_string(x = r, fill = r)) + 
      geom_histogram(fill = "violetred", alpha = 0.5, bins = 50) + 
      ylab("Histogram") +
      ggtitle(paste0(r)) +
      theme_classic() + 
      theme(axis.text.x = element_text(angle = 90),
            axis.title.x = element_text())
  )
}
```

## Bivariate Plots {.tabset .tabset-fade .tabset-pills}

* Plots to illustrate pairwise relationships amongst variables.

### Categorical-Categorical

```{r explorecatcat, warning = FALSE}
for(r in 1:length(facnames.mod)) # loop across all factors
{
  for(i in 1:length(facnames.mod)) # inner loop
  {
    if(i == r | i < r) 
    { # dont do anything if they are the same or the graph has been made before
    } else {
      tempform <- paste0("~ ", facnames.mod[r], " + ", facnames.mod[i])  # create formula for xtabs
      # temp is a dataframe that is only going to exist in this section and overwritten with each loop
      temp <- as.data.frame(xtabs(eval(parse(text = tempform)),
                                  data = mydata,
                                  subset = NULL))
      plot(
        ggplot(data = temp, aes_string(x = facnames.mod[r], y = facnames.mod[i], fill = "Freq", label = "Freq")) +
          geom_tile() + 
          geom_text() + 
          scale_fill_gradient(low = "white", high = "violetred") + 
          theme_minimal() + 
          theme(axis.text.x = element_text(angle = 90),
                legend.position = "none")
      )
    }
  }
}
```

### Continuous-Continuous

```{r exploreconcon, warning = FALSE}
for(r in 1:length(numnames)) # loop across all numeric columns
{
  for(i in 1:length(numnames)) # inner loop
  {
    if(i == r | i < r)
    { # dont do anything if they are the same or the graph has been made before
    } else {
      # create formulas for lm()
      tempform.std <- paste0("scale(", numnames[i],")", " ~ ", "scale(", numnames[r], ")") # standardized
      tempform <- paste0(numnames[i], " ~ ", numnames[r]) # unstandardized
      # regress to get best fit line
      stdreg <- lm(eval(parse(text = tempform.std)),
                   data = mydata) # standardized
      reg <- lm(eval(parse(text = tempform)),
                data = mydata) # unstandardized
      
      plot(
        ggplot(data = mydata, aes_string(x = numnames[r], y = numnames[i])) +
          geom_point(color = "violetred", size = 2, alpha = 0.3) +
          theme_classic() + 
          geom_abline(slope = reg$coefficients[2], intercept = reg$coefficients[1], lty = "dashed") + 
          geom_label(aes(x = Inf, y = Inf, label = paste0("Standardized Regression Coefficient = ",
                                                          round(stdreg$coefficients[2],3)),
                         hjust = 1, vjust = 2)) + 
          theme(axis.text.x = element_text(angle = 90))
      )
    }
  }
}
```

### Continuous-Categorical

```{r exploreconcat, warning = FALSE}
for(r in facnames.mod) # loop across all factor columns
{
  for(i in numnames) # inner loop across all numeric columns
  {
    plot(
      ggplot(data = mydata, aes_string(x = r, y = i, fill = r)) + 
        geom_boxplot() + 
        theme_classic() + 
        theme(legend.position = "none",
              axis.text.x = element_text(angle = 90))
    )
  }
}
```

### Correlation Matrix

```{r corrmatrix}
corrplot.mixed(cor(mydata[,grep(paste0(numnames.time, collapse = "|"), names(mydata))]), # only get the numeric columns
               upper = "color",
               tl.pos = "lt",
               tl.cex = 0.5,
               cl.cex = 0.5)
```

# Phase 5: Answering Questions

## Most/Least Popular Level 4 Module {.tabset .tabset-fade .tabset-pills}

### Quota At Round 1A

```{r quota1a, out.height = "90%", fig.width = 12}
    mydata %>%
  filter(Level ==  "Level 4") %>%
  filter(Round == "1A") %>%
filter(Quota >= 40) %>%
  filter(BidPerQuota > 1) %>%
  arrange(-LowestSuccessfulBid) %>%
  ggplot(mapping = aes(y = ModuleCode, x = AcadYear, fill = LowestSuccessfulBid, label = ModuleTitle)) +
  geom_tile(show.legend = TRUE) +
  theme_classic() +
  facet_wrap(~ Semester, ncol = 2) + 
  theme(axis.text.x = element_text(angle = 90), 
          legend.position = "top",
          strip.background = element_rect(fill = "grey30", linetype = "blank"),
          strip.text = element_text(color = "white", size = 12)) + 
  scale_fill_gradient(low = "grey90", high = "red")
```

### Lowest Successful Bid

```{r lsb, out.height = "60%"}
ggplotly(
  mydata %>%
  filter(Level ==  "Level 4") %>%
  filter(Round == "1A") %>%
  group_by(ModuleCode, ModuleTitle) %>%
  summarize(LSB.avg.sem.years = mean(LowestSuccessfulBid)) %>%
  ungroup() %>%
  mutate(ModuleCode = fct_reorder(ModuleCode, LSB.avg.sem.years)) %>%
  ggplot(mapping = aes(x = ModuleCode, y = LSB.avg.sem.years, label = ModuleTitle, fill = LSB.avg.sem.years)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_classic() +
  theme(legend.position = "none")
, tooltip = c("x", "label", "y")
, height = 600, width = 400
)
```

### BPQ

```{r bpq, out.height = "60%"}
ggplotly(
  mydata %>%
  filter(Level ==  "Level 4") %>%
  filter(Round == "1A") %>%
  group_by(ModuleCode, ModuleTitle) %>%
  summarize(BPQ.avg.sem.years = mean(BidPerQuota)) %>%
  ungroup() %>%
  mutate(ModuleCode = fct_reorder(ModuleCode, BPQ.avg.sem.years)) %>%
  ggplot(mapping = aes(x = ModuleCode, y = BPQ.avg.sem.years, label = ModuleTitle, fill = BPQ.avg.sem.years)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_classic() +
  theme(legend.position = "none")
, tooltip = c("x", "label", "y")
, height = 600, width = 400
)
```

### Quota

```{r quota, out.height = "60%"}
ggplotly(
  mydata %>%
  filter(Level ==  "Level 4") %>%
  filter(Round == "1A") %>%
  group_by(ModuleCode, ModuleTitle) %>%
  summarize(quota.avg.sem.years = mean(Quota)) %>%
  ungroup() %>%
  mutate(ModuleCode = fct_reorder(ModuleCode, quota.avg.sem.years)) %>%
  ggplot(mapping = aes(x = ModuleCode, y = quota.avg.sem.years, label = ModuleTitle, fill = quota.avg.sem.years)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_classic() +
  theme(legend.position = "none")
, tooltip = c("x", "label", "y")
, height = 600, width = 400
)
```

## Do less people bid for a module if the lecture begins in the morning (before 12pm)?

Lets look at each module and compare the average **number of bidders**, **bidders per quota** and **lowest successful bids** when the lecture begins in and after the morning.

### By Module

```{r bymod, fig.width = 15, fig.height = 15, out.height = "90%", out.width = "90%"}
for(r in c("meanBidders", "meanBpQ", "meanLSB"))
{
  plot(mydata %>%
    group_by(ModuleCode, ModuleTitle, Period) %>%
    summarise(meanBidders = mean(Bidders), meanBpQ = mean(BidPerQuota), meanLSB = mean(LowestSuccessfulBid),
              sdBidders = sd(Bidders), sdBpQ = sd(BidPerQuota), sdLSB = mean(LowestSuccessfulBid)) %>%
    ggplot(aes_string(x = "Period", y = r, fill = "Period")) +
    geom_bar(stat = "identity") +
    theme_classic() +  
    theme(axis.text.x = element_blank(), 
          legend.position = "top",
          strip.background = element_rect(fill = "grey30", linetype = "blank"),
          strip.text = element_text(color = "white", size = 12)) + 
    facet_grid(~ ModuleCode:ModuleTitle, labeller = label_wrap_gen(width = 25)) +
    ggtitle(r))
}
```

### By Level

```{r bylevel}
for(r in c("meanBidders", "meanBpQ", "meanLSB"))
{
  plot(mydata %>%
    group_by(Level, Period) %>%
    summarise(meanBidders = mean(Bidders), meanBpQ = mean(BidPerQuota), meanLSB = mean(LowestSuccessfulBid),
              sdBidders = sd(Bidders), sdBpQ = sd(BidPerQuota), sdLSB = mean(LowestSuccessfulBid)) %>%
    ggplot(aes_string(x = "Period", y = r, fill = "Period")) +
    geom_bar(stat = "identity") +
    theme_classic() +  
    theme(axis.text.x = element_blank(), 
          legend.position = "top",
          strip.background = element_rect(fill = "grey30", color = "black"),
          strip.text = element_text(color = "white", size = 12)) + 
    facet_wrap(~ Level) +
    ggtitle(r))
}
```

### Bonus: Multilevel Modeling

#### Removal Of Modules With...{.tabset}

##### Less Than 3 Instances

```{r}
mymlm <- mydata %>%
  group_by(ModuleCode) %>%
  filter(n() >= 3)
```

##### With No Variability In `StartTime`

```{r}
# # remove those with no variability in StartTime
mymlm <- mydata %>%
  group_by(ModuleCode) %>%
  mutate(sdBpQ = sd(BidPerQuota), sdStartTime = sd(StartTime)) %>%
  filter(sdStartTime > 0) %>%
  arrange(sdBpQ)
```

##### Hours From 12am `Hrs12` And Group-Mean Centered `Hrs12`.

```{r}
mymlm <- mymlm %>% 
  mutate(Hrs12 = StartTime/100) %>%
  group_by(ModuleCode) %>%
  arrange()
```

##### Peek Data

```{r}
head(mymlm)
```

#### Models

##### Baseline Model

```{r, eval = FALSE}
fit0 <- lmer(BidPerQuota ~ 1 + (1 | ModuleCode),
     data = mymlm)
VarCorr(fit0)

(0.3672^2)/((0.3672^2) + (0.67259^2))
```

##### With Hrs12.gmc

```{r, eval = FALSE}
fit1 <- lmer(avgLSB ~ Level*Hrs12.gmc + (1 | ModuleCode),
     data = mymlm)
summary(fit1)
car::Anova(fit1)
```

## Do results from previous rounds...

```{r}
head(mydata)

a <- mydata %>%
  pivot_wider(names_from = Round,
         values_from = BidPerQuota
         )

```

## are there dumping

